{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:25:17.047181Z",
     "start_time": "2025-10-15T17:25:17.039662Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "id": "7fba52937e936a3f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-15T17:33:59.393726Z",
     "start_time": "2025-10-15T17:29:39.084306Z"
    }
   },
   "source": [
    "from transformers import AutoModel\n",
    "model = AutoModel.from_pretrained('bert-base-cased')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4d75813d1caf415381458f3844a4c801"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dawood Khan\\anaconda3\\envs\\llm\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Dawood Khan\\.cache\\huggingface\\hub\\models--bert-base-cased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8019b83ff5964f0f92398950e87e27f5"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:36:35.110817Z",
     "start_time": "2025-10-15T17:36:34.322402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# If one knows which model to use then he/she can import specified Class of the model\n",
    "from transformers import BertModel\n",
    "model = BertModel.from_pretrained('bert-base-cased')"
   ],
   "id": "b9de4e061c42043",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:37:30.107948Z",
     "start_time": "2025-10-15T17:37:29.695397Z"
    }
   },
   "cell_type": "code",
   "source": "model.save_pretrained('llm model/')",
   "id": "bfd22439f577b5c4",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:38:14.460987Z",
     "start_time": "2025-10-15T17:38:14.310963Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# laoding the saved model\n",
    "from transformers import AutoModel\n",
    "model = AutoModel.from_pretrained('llm model/')"
   ],
   "id": "36ba6ad023355b0f",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:38:18.179075Z",
     "start_time": "2025-10-15T17:38:18.171077Z"
    }
   },
   "cell_type": "code",
   "source": "model",
   "id": "e295cac73d3e620f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:42:03.134117Z",
     "start_time": "2025-10-15T17:41:59.269318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')"
   ],
   "id": "ac6650fa72e87d26",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9c54245e31334b2b8e7e9a92e1e4b6d1"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "91982b7b773b4125984dd0463cb3aad6"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "733dae5feafa4ad8bc4087f1bd32a768"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:42:48.438017Z",
     "start_time": "2025-10-15T17:42:48.431018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "encoded_input = tokenizer('Hi I am Dawood')\n",
    "print(encoded_input)"
   ],
   "id": "df80cf1cbd4f2c5e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 8790, 146, 1821, 10136, 2615, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:44:05.436089Z",
     "start_time": "2025-10-15T17:44:05.430089Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.decode(encoded_input['input_ids'])",
   "id": "ee1131213434aa7b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] Hi I am Dawood [SEP]'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:46:23.869455Z",
     "start_time": "2025-10-15T17:46:23.863456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# We can encode multiple sentences\n",
    "encoded_input = tokenizer('This is an example text', 'How are you?', 'What is that ?', return_tensors='pt')\n",
    "print(encoded_input)"
   ],
   "id": "453eb15ea3bee8c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 101, 1188, 1110, 1126, 1859, 3087,  102, 1731, 1132, 1128,  136,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'labels': tensor([[ 101, 1327, 1110, 1115,  136,  102]])}\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:48:50.815846Z",
     "start_time": "2025-10-15T17:48:50.809845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# If we add padding then all the sentences will become of the same length\n",
    "encoded_input = tokenizer('This is an example text', 'How are you?', 'What is that ?', padding = True,return_tensors='pt')\n",
    "print(encoded_input)"
   ],
   "id": "6c1f815b1dab1394",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 101, 1188, 1110, 1126, 1859, 3087,  102, 1731, 1132, 1128,  136,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'labels': tensor([[ 101, 1327, 1110, 1115,  136,  102]])}\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:51:17.713951Z",
     "start_time": "2025-10-15T17:51:17.706952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## If you have sequences longer than the model can handle, you’ll need to truncate them with the truncation parameter\n",
    "encoded_input = tokenizer('I am going to write a very long sentence. This is will be longer than what the model can tokenize and thus it is a very very very very very very very long sentence. I hope you understand', truncation=True, return_tensors='pt')\n",
    "print(encoded_input)"
   ],
   "id": "f1478873a7280482",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,   146,  1821,  1280,  1106,  3593,   170,  1304,  1263,  5650,\n",
      "           119,  1188,  1110,  1209,  1129,  2039,  1190,  1184,  1103,  2235,\n",
      "          1169, 22559,  3708,  1105,  2456,  1122,  1110,   170,  1304,  1304,\n",
      "          1304,  1304,  1304,  1304,  1304,  1263,  5650,   119,   146,  2810,\n",
      "          1128,  2437,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:52:50.019859Z",
     "start_time": "2025-10-15T17:52:50.013849Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# By combining truncation and padding we can have exact size tensors\n",
    "encoded_input = tokenizer(['How is the day?', 'WHo are you?'],\n",
    "                          padding = True,\n",
    "                          truncation=True,\n",
    "                          max_length=5,\n",
    "                          return_tensors='pt')\n",
    "print(encoded_input)"
   ],
   "id": "e4a0df0bc937ad32",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 101, 1731, 1110, 1103,  102],\n",
      "        [ 101,  160, 3048, 1186,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:54:45.871015Z",
     "start_time": "2025-10-15T17:54:45.865012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "encoded_input = tokenizer('I am learning LLMs')\n",
    "print(encoded_input)\n",
    "tokenizer.decode(encoded_input['input_ids'])# [CLS] and [SEP] are special tokens which tell the start and end of a sentence respectively to the model"
   ],
   "id": "66f6d57a85d243f7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 146, 1821, 3776, 12427, 25866, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[CLS] I am learning LLMs [SEP]'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:57:12.652641Z",
     "start_time": "2025-10-15T17:57:12.648641Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sequences = ['It has been a very good day for me so far',\n",
    "             'I am playing Football now.']"
   ],
   "id": "8a3161e3fcef9fb8",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:59:59.503233Z",
     "start_time": "2025-10-15T17:59:59.496236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "encoded_sequences = tokenizer(sequences, padding =True, truncation=True, max_length= 10, return_tensors='pt')\n",
    "print(encoded_sequences)"
   ],
   "id": "59de1a7f22404344",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 101, 1135, 1144, 1151,  170, 1304, 1363, 1285, 1111,  102],\n",
      "        [ 101,  146, 1821, 1773, 2289, 1208,  119,  102,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0]])}\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T18:00:44.402161Z",
     "start_time": "2025-10-15T18:00:44.395159Z"
    }
   },
   "cell_type": "code",
   "source": "encoded_sequences['input_ids'].dtype",
   "id": "3c05cbc26020239c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T18:00:58.359927Z",
     "start_time": "2025-10-15T18:00:58.354927Z"
    }
   },
   "cell_type": "code",
   "source": "model_inputs = encoded_sequences",
   "id": "f68fdcaa5a650e81",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T18:02:25.911691Z",
     "start_time": "2025-10-15T18:02:25.778659Z"
    }
   },
   "cell_type": "code",
   "source": "output = model(**model_inputs)",
   "id": "347c95f75bc9b5a1",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T18:04:30.225401Z",
     "start_time": "2025-10-15T18:04:30.219412Z"
    }
   },
   "cell_type": "code",
   "source": "output.last_hidden_state.shape",
   "id": "9e9cd54e2b23949a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 768])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T18:04:30.262926Z",
     "start_time": "2025-10-15T18:04:30.255926Z"
    }
   },
   "cell_type": "code",
   "source": "output.last_hidden_state",
   "id": "55e379e2ba316b07",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2854,  0.0338, -0.0821,  ..., -0.1121,  0.2115,  0.3503],\n",
       "         [ 0.0571, -0.0335, -0.0437,  ...,  0.4303, -0.3569,  1.0744],\n",
       "         [ 0.3485,  0.2078,  0.1533,  ...,  0.0530,  0.0401,  0.6579],\n",
       "         ...,\n",
       "         [-0.0381, -0.3201,  0.2981,  ...,  0.8228, -0.0160,  0.6550],\n",
       "         [ 0.0331, -0.1404,  0.1071,  ..., -0.0650, -0.0649,  0.3991],\n",
       "         [ 0.9315,  0.2287, -0.7739,  ...,  0.5777,  0.5007,  0.3352]],\n",
       "\n",
       "        [[ 0.4203,  0.1009, -0.0511,  ...,  0.1172,  0.4835, -0.0227],\n",
       "         [ 0.4063, -0.2300,  0.5612,  ...,  0.0990,  0.1991,  0.0607],\n",
       "         [-0.2074, -0.0577,  0.2309,  ...,  0.3561, -0.2252, -0.0376],\n",
       "         ...,\n",
       "         [ 0.8052,  0.3366, -0.0916,  ...,  0.5053,  1.0640, -0.3916],\n",
       "         [ 0.0863,  0.1791,  0.0923,  ...,  0.3198,  0.3039,  0.1620],\n",
       "         [ 0.0653,  0.0835,  0.0977,  ...,  0.2915,  0.3027,  0.1995]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "70afd0deecce94b5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
